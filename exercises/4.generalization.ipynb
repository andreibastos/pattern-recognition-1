{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((210, 7), (210,), {1, 2, 3})"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = fetch_openml(data_id='1499')\n",
    "X, y = dataset.data, dataset.target.astype(int)\n",
    "X.shape, y.shape, set(y)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Modelos de Avaliação"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificadores\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# divisao do dataset\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "\n",
    "# preprocessamento\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MaxAbsScaler\n",
    "\n",
    "# métricas \n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "\n",
    "# extras\n",
    "import numpy as np \n",
    "\n",
    "# ---------------------------------------------------\n",
    "# sem realizar nenhum pré processamento\n",
    "params_model_1_knn = {'n_neighbors':[3, 5 , 7]}\n",
    "params_model_1_logistic = {'fit_intercept':[True, False]}\n",
    "model_1_knn = GridSearchCV(KNeighborsRegressor(), params_model_1_knn)\n",
    "model_1_logistic = GridSearchCV(LogisticRegression(), params_model_1_logistic)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# realizando um pré processamento Normalizer\n",
    "pipeline_2_knn = Pipeline([\n",
    "    ('normalize', Normalizer()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "pipeline_2_logistic = Pipeline([\n",
    "    ('normalize', Normalizer()),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "model_2_knn = GridSearchCV(pipeline_2_knn, \n",
    "{'knn__n_neighbors':[3, 5 , 7]}, scoring='explained_variance')\n",
    "\n",
    "model_2_logistic = GridSearchCV(pipeline_2_logistic, {'logistic__fit_intercept':[True, False]}, scoring='explained_variance')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# realizando um pré processamento StandardScaler\n",
    "pipeline_3_knn = Pipeline([\n",
    "    ('normalize', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "pipeline_3_logistic = Pipeline([\n",
    "    ('normalize', StandardScaler()),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "model_3_knn = GridSearchCV(pipeline_3_knn,{'knn__n_neighbors':[3, 5 , 7]}, scoring='explained_variance')\n",
    "model_3_logistic = GridSearchCV(pipeline_3_logistic,{'logistic__fit_intercept':[True, False]}, scoring='explained_variance')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# realizando um pré processamento MaxAbsScaler\n",
    "pipeline_4_knn = Pipeline([\n",
    "    ('normalize', MaxAbsScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "pipeline_4_logistic = Pipeline([\n",
    "    ('normalize', MaxAbsScaler()),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "model_4_knn = GridSearchCV(pipeline_4_knn,{'knn__n_neighbors':[3, 5 , 7]}, scoring='explained_variance')\n",
    "model_4_logistic = GridSearchCV(pipeline_4_logistic,{'logistic__fit_intercept':[True, False]}, scoring='explained_variance')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# prepara a lista de avaliações\n",
    "evaluates = {\n",
    "    1 : {'knn':model_1_knn, 'logistic':model_1_logistic, 'data':[], 'title':'Sem Pré-processamento'},\n",
    "    2 : {'knn':model_2_knn, 'logistic':model_2_logistic, 'data':[], 'title':'Com Normalizer'},\n",
    "    3 : {'knn':model_3_knn, 'logistic':model_3_logistic, 'data':[], 'title':'Com StandardScaler'},\n",
    "    4 : {'knn':model_4_knn, 'logistic':model_4_logistic, 'data':[], 'title':'Com MaxAbsScaler'},\n",
    "}\n"
   ]
  },
  {
   "source": [
    "# Avaliações"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# realização 10 repetições do kfold, para k=5 (5 folds)\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=150)\n",
    "\n",
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\" função para treinar o modelo,  realizar a predição e calcular as métricas \n",
    "    \"\"\"\n",
    "    # treina e realiza a predição\n",
    "    model.fit(X_train, y_train)\n",
    "    ypred = model.predict(X_test)\n",
    "\n",
    "    # calcula as métricas\n",
    "    hits  = ypred == y_test\n",
    "    hits_percent = sum(hits)/len(hits)   # hits \n",
    "    neg_msle = mean_squared_log_error(y_test, ypred)   \n",
    "    root_mse = mean_squared_error(y_test, ypred, squared=False) \n",
    "    return [hits_percent, neg_msle, root_mse]\n",
    "\n",
    "# para cada repetição de kfold\n",
    "for train_index, test_index in rkf.split(X):\n",
    "    # obtém os dados da repetição i\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # para cada classificador \n",
    "    for classifier in classifiers:        \n",
    "        # calcula os resultados do knn\n",
    "        result_knn = evaluate(classifier['knn'], X_train, y_train, X_test, y_test)\n",
    "        # calcula os resultados do logistic\n",
    "        result_logistic = evaluate(classifier['logistic'], X_train, y_train, X_test, y_test)\n",
    "\n",
    "        # adiciona na lista da respectiva avaliação\n",
    "        evaluates[classifier['id']]['data'].append([result_knn, result_logistic])"
   ]
  },
  {
   "source": [
    "# Apresentação dos resultados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------------------------------------\nAvaliação 1 - Sem Pré-processamento\n\tKNN:      hits: 74.14%,       mean_squared_log_error: 2.51%,       root_mse: 42.28%\n\tLogistic: hits: 91.76%,       mean_squared_log_error: 2.72%,       root_mse: 44.02%\n\n------------------------------------------------------------------------------------------\nAvaliação 2 - Com Normalizer\n\tKNN:      hits: 71.57%,       mean_squared_log_error: 2.35%,       root_mse: 41.23%\n\tLogistic: hits: 79.81%,       mean_squared_log_error: 5.89%,       root_mse: 66.22%\n\n------------------------------------------------------------------------------------------\nAvaliação 3 - Com StandardScaler\n\tKNN:      hits: 72.95%,       mean_squared_log_error: 2.11%,       root_mse: 38.59%\n\tLogistic: hits: 92.57%,       mean_squared_log_error: 2.67%,       root_mse: 44.10%\n\n------------------------------------------------------------------------------------------\nAvaliação 4 - Com MaxAbsScaler\n\tKNN:      hits: 72.67%,       mean_squared_log_error: 2.51%,       root_mse: 42.58%\n\tLogistic: hits: 88.14%,       mean_squared_log_error: 4.27%,       root_mse: 56.17%\n\n"
     ]
    }
   ],
   "source": [
    "# para cada avalição realizada\n",
    "for e in evaluates:\n",
    "    # dados da avalição\n",
    "    data = np.array(evaluates[e]['data'])\n",
    "    title = evaluates[e]['title']    \n",
    "\n",
    "    # métricas\n",
    "    ## hits \n",
    "    knn_mean_hits = np.mean(data[:, 0, 0])*100\n",
    "    logistic_mean_hits = np.mean(data[:, 1, 0])*100\n",
    "\n",
    "    ## mean squared log_error\n",
    "    knn_mean_mslr = np.mean(data[:, 0, 1])*100\n",
    "    logistic_mean_mslr = np.mean(data[:, 1, 1])*100\n",
    "\n",
    "    ## mean squared error\n",
    "    knn_mean_rmse = np.mean(data[:, 0, 2])*100\n",
    "    logistic_mean_rmse = np.mean(data[:, 1, 2])*100\n",
    "    \n",
    "    print('---'*30)\n",
    "    print(f'Avaliação {e} - {title}')\n",
    "    print(f'\\tKNN: {\"\":5}hits: {knn_mean_hits:.2f}%, {\"\":5} mean_squared_log_error: {knn_mean_mslr:.2f}%, {\"\":5} root_mse: {knn_mean_rmse:.2f}%')\n",
    "    print(f'\\tLogistic: hits: {logistic_mean_hits:.2f}%, {\"\":5} mean_squared_log_error: {logistic_mean_mslr:.2f}%, {\"\":5} root_mse: {logistic_mean_rmse:.2f}%')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{}"
   ]
  }
 ]
}